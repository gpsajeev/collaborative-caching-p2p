{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "name": "",
  "signature": "sha256:68803e3bb0060745ef26d75bf082f90ce4058ad2c6a921dc987be7592ba9007b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "from decimal import *\n",
      "import DecisionTree\n",
      "import random \n",
      "import numpy as np\n",
      "import os\n",
      "import operator\n",
      "cache_request=0\n",
      "total_request=0\n",
      "cache_byte=0\n",
      "total_byte=0\n",
      "#N=2\n",
      "L=1\n",
      "w_old=[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]\n",
      "\n",
      "peer_cache=[]\n",
      "lines=[]\n",
      "close_friend_set=[]\n",
      "DESIRED_COLUMNS=('object_id','Size')\n",
      "f=open(\"input_sam2.csv\")\n",
      "reader=csv.reader(f)\n",
      "headers = None\n",
      "results = []\n",
      "for row in reader:\n",
      "    if not headers:\n",
      "        headers = []\n",
      "        for i, col in enumerate(row):\n",
      "         if col in DESIRED_COLUMNS:\n",
      "            # Store the index of the cols of interest\n",
      "            headers.append(i)\n",
      "\n",
      "    else:\n",
      "       results.append(tuple([row[i] for i in headers]))\n",
      "r=[]\n",
      "r=dict(list(set(results)))\n",
      "\n",
      "def datastore_init(data_store_pa,n):\n",
      "    n1=n\n",
      "    n=n+1\n",
      "    n=str(n)\n",
      "    \n",
      "    num1= raw_input('Enter the No.of data to be cached in the peer cache '+n+':')\n",
      "    num1=int(num1)\n",
      "    \n",
      "    for j in range(0,num1):\n",
      "        data=raw_input('Enter the data to be entered:') \n",
      "        data_store_pa[data]=1\n",
      "        print data_store_pa\n",
      "    peer_cache.insert(n1,data_store_pa)\n",
      "def decn():\n",
      "        global dt\n",
      "        global root_node\n",
      "        training_datafile = \"input_sam2.csv\"\n",
      "        dt = DecisionTree.DecisionTree(\n",
      "                training_datafile = training_datafile,\n",
      "                csv_class_column_index = 8,\n",
      "                csv_columns_for_features = [2,3,4,7],\n",
      "                entropy_threshold = 0.01,\n",
      "                max_depth_desired = 8,\n",
      "                symbolic_to_numeric_cardinality_threshold = 10)\n",
      "\n",
      "        dt.get_training_data()\n",
      "        dt.calculate_first_order_probabilities()\n",
      "        #dt.calculate_class_priors()\n",
      "        #dt.show_training_data()\n",
      "        root_node = dt.construct_decision_tree_classifier()\n",
      "        #root_node.display_decision_tree(\"   \") \n",
      "        \n",
      "def get_probability(remove_item):\n",
      "        request=remove_item\n",
      "        training_datafile = \"new_file.csv\"\n",
      "        dt1 = DecisionTree.DecisionTree(\n",
      "                training_datafile = training_datafile,\n",
      "                csv_class_column_index = 8,\n",
      "                csv_columns_for_features = [2,3,4,7],\n",
      "                entropy_threshold = 0.01,\n",
      "                max_depth_desired = 8,\n",
      "                symbolic_to_numeric_cardinality_threshold = 10)\n",
      "\n",
      "        dt1.get_training_data()\n",
      "        dt1.calculate_first_order_probabilities()\n",
      "        #dt.calculate_class_priors()\n",
      "        #dt.show_training_data()\n",
      "        root_node = dt1.construct_decision_tree_classifier()\n",
      "        #root_node.display_decision_tree(\"   \") \n",
      "        with open(\"input_sam2.csv\", 'rb') as f:\n",
      "             reader = csv.DictReader(f)\n",
      "             rows = [row for row in reader if row['object_id'] == request]\n",
      "             t1=rows[0]['object_id']\n",
      "             t2=rows[0]['Recency']\n",
      "             t3=rows[0]['Frequency']\n",
      "             t4=rows[0]['SWL_frequency']\n",
      "             t5=rows[0]['Retrieval_time']\n",
      "             t6=rows[0]['Size']\n",
      "             t7=rows[0]['Type']\n",
      "             t1=int(t1)\n",
      "             t2=int(t2)\n",
      "             t3=int(t3)\n",
      "             t4=int(t4)\n",
      "             t5=int(t5)\n",
      "             t6=int(t6)\n",
      "             t7=int(t7)\n",
      "   \n",
      "             test_sample  = [\"Recency=%d\"% t2,\n",
      "                  \"Frequency=%d\"% t3,\n",
      "                  \"SWL_frequency=%d\"% t4,\n",
      "                    \"Type=%d\"% t7]\n",
      "             classification = dt.classify(root_node, test_sample)\n",
      "             #print \"Classification: \", classification\n",
      "             #print \"Revisiting Probability:\",classification['Target=\"1\"']\n",
      "    \n",
      "             new_p = classification['Target=\"1\"']\n",
      "             return new_p\n",
      "    \n",
      "        \n",
      "        \n",
      "def Cost_functn(i):\n",
      "        t=int(r.get(i))\n",
      "        c=2+t/536\n",
      "        return c        \n",
      "def IGDS(request,n):\n",
      "   \n",
      "    with open(\"input_sam2.csv\", 'rb') as f:\n",
      "     reader = csv.DictReader(f)\n",
      "     rows = [row for row in reader if row['object_id'] == request]\n",
      "     t1=rows[0]['object_id']\n",
      "     t2=rows[0]['Recency']\n",
      "     t3=rows[0]['Frequency']\n",
      "     t4=rows[0]['SWL_frequency']\n",
      "     t5=rows[0]['Retrieval_time']\n",
      "     t6=rows[0]['Size']\n",
      "     t7=rows[0]['Type']\n",
      "     t1=int(t1)\n",
      "     t2=int(t2)\n",
      "     t3=int(t3)\n",
      "     t4=int(t4)\n",
      "     t5=int(t5)\n",
      "     t6=int(t6)\n",
      "     t7=int(t7)\n",
      "   \n",
      "    test_sample  = [\n",
      "                    \"Recency=%d\"% t2,\n",
      "                  \"Frequency=%d\"% t3,\n",
      "                  \"SWL_frequency=%d\"% t4,\n",
      "                    \"Type=%d\"% t7]\n",
      "    classification = dt.classify(root_node, test_sample)\n",
      "    #print \"Classification: \", classification\n",
      "    print \"Revisiting Probability:\",classification['Target=\"1\"']\n",
      "    \n",
      "    P = classification['Target=\"1\"']\n",
      "    \n",
      "    val=request\n",
      "    n=int(n)\n",
      "    size=int(r.get(val))\n",
      "    cost=Cost_functn(val)\n",
      "    cost=int(cost)\n",
      "    Cache=peer_cache[n]\n",
      "    i=Cache.keys().index(val)\n",
      "   \n",
      "    W_new=float(w_old[i])+float(P)\n",
      "    w_old[i]=W_new\n",
      "    W_new=float(W_new)\n",
      " \n",
      "    new_val=L+W_new*float(cost)/float(size)\n",
      "    return new_val\n",
      "    print \"-----------------------------------------------------------------------------\"\n",
      "    \n",
      "    \n",
      "def auctioning(n,remove_item):\n",
      "    print \"***********************************************************\"\n",
      "    print \"                   Auctioning happens                      \"\n",
      "    print \"************************************************************\"\n",
      "    n1=n\n",
      "    n1=str(n1)\n",
      "    print \"close friend set of peer \" + n1\n",
      "    probility_list={}\n",
      "    for a in close_friend_set[n]:\n",
      "        with open(\"input_sam3.csv\", \"rb\") as source:\n",
      "            lines = [line for line in source]\n",
      "        random_choice = random.sample(lines, 50)\n",
      "        with open(\"new_file1.csv\", \"wb\") as sink:\n",
      "            sink.write(\"\".join(random_choice))\n",
      "        p=get_probability(remove_item)\n",
      "        probility_list[a]=p\n",
      "        os.remove(\"new_file1.csv\")\n",
      "    print \"probability list\"\n",
      "    print probility_list\n",
      "    if probility_list:\n",
      "     v=list(probility_list.values())\n",
      "     k=list(probility_list.keys())\n",
      "     maxi= k[v.index(max(v))]\n",
      "     m=maxi\n",
      "     m=str(m)\n",
      "     print \"The removed item pushed into peer cache \"+m\n",
      "     add_new_item(remove_item,maxi)\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "def  add_new_item(request,n):\n",
      "    n=int(n)\n",
      "    if len(peer_cache[n])!=N:\n",
      "        peer_cache[n][request]=1\n",
      "        print \"After the updation.................Cache is\"\n",
      "        print peer_cache[n]\n",
      "        print \"----------------------------------------------\"\n",
      "    else:\n",
      "        print \"Need to evict elements to make rooms for the new ones\"\n",
      "        remove_item = min(peer_cache[n], key=peer_cache[n].get)\n",
      "        remove_item=str(remove_item)\n",
      "        min_val=min(peer_cache[n].itervalues())\n",
      "        print min_val\n",
      "        L=min_val\n",
      "        print \"cache is full,one element need to remove.Removed element is\",remove_item\n",
      "        del peer_cache[n][remove_item]\n",
      "        print \"----------------------------------------------\"\n",
      "        print \"After the deletion.................Cache is\"\n",
      "        print peer_cache[n]\n",
      "        print \"----------------------------------------------\"\n",
      "        peer_cache[n][request]=1\n",
      "        print \"----------------------------------------------\"\n",
      "        print \"After the modification................Cache is\"\n",
      "        print peer_cache[n]\n",
      "        print \"----------------------------------------------\"\n",
      "        \n",
      "        auctioning(n,remove_item)\n",
      "        \n",
      "        \n",
      "    \n",
      "    \n",
      "\n",
      "        \n",
      "        \n",
      "def cachemanager(request,n):\n",
      "    global cache_request\n",
      "    global cache_byte\n",
      "    flag=0\n",
      "    n=int(n)\n",
      "    n2=request\n",
      "    n2=str(n2)\n",
      "    \n",
      "    \n",
      "    if request in peer_cache[n]:\n",
      "        n1=n\n",
      "        cache_request=cache_request+1\n",
      "        n1=str(n1)\n",
      "        data1=0\n",
      "                   \n",
      "        data1=r[n2]\n",
      "        cache_byte=int(cache_byte)+int(data1)\n",
      "        print \"Requested data item found in peer \" + n1 +\" local cache\"\n",
      "        print \"-----------------------------------------------------------------------------\"\n",
      "\n",
      "        new_value=IGDS(request,n)\n",
      "        peer_cache[n][request]=new_value\n",
      "        print \"After the updation.................Cache is\"\n",
      "        print peer_cache[n]\n",
      "        print \"----------------------------------------------\"\n",
      "        \n",
      "\n",
      "        \n",
      "        \n",
      "    else:\n",
      "        print \"Contacting its close friend set.........................\"\n",
      "        print \"............................................................\"\n",
      "        print \"............................................................\"\n",
      "        print \"............................................................\"\n",
      "\n",
      "        b=close_friend_set[n]\n",
      "        for a in b:\n",
      "            if request in peer_cache[a]:\n",
      "                a=str(a)\n",
      "                flag=1\n",
      "                cache_request=cache_request+1\n",
      "                data2=0\n",
      "                   \n",
      "                data2=r[n2]\n",
      "                cache_byte=int(cache_byte)+int(data2)\n",
      "\n",
      "                print \"the requested data in the peer\"+ a\n",
      "                a=int(a)\n",
      "                new_value=IGDS(request,a)\n",
      "                peer_cache[a][request]=new_value\n",
      "                break\n",
      "        \n",
      "        if flag==0:\n",
      "          print \"Not in closest neighbours...contacting the server\"\n",
      "          add_new_item(request,n)\n",
      "        else:\n",
      "          print \"After the updation.................Cache is\"\n",
      "          print peer_cache[a]\n",
      "          print \"----------------------------------------------\"\n",
      "        \n",
      "def close_friend_calculation(a,size):\n",
      "    print \"----------------------------------------------\"\n",
      "    for i in range(0,size):\n",
      "        cf=[]\n",
      "        for j in range(0,size):\n",
      "            if a[i][j]>10:\n",
      "                if j!=i:\n",
      "                 cf.append(j)\n",
      "        close_friend_set.insert(i,cf)\n",
      "    print \"close friend set of each peers\"\n",
      "    for i in range(0,size):\n",
      "        j=i\n",
      "        j=str(j)\n",
      "        m=str(close_friend_set[i])\n",
      "        print \"close friend set of peer\" + j + \":\" + m\n",
      "    print \"----------------------------------------------\"\n",
      "\n",
      "   \n",
      "def inter_meeting_time_matrix(size):\n",
      "    inter_meeting=np.random.uniform(2,15,[size,size])\n",
      "    print \"-----------------------------------------------------------------------------\"\n",
      "    print \"Inter meeting time between the peers\"\n",
      "    print inter_meeting\n",
      "    link_quality=[[0 for x in range(size)] for x in range(size)] \n",
      "    T=50\n",
      "    \n",
      "    for i in range(0,size):\n",
      "        for j in range(0,size):\n",
      "            link_quality[i][j]=2*T/inter_meeting[i][j]\n",
      "    l=np.array(link_quality)\n",
      "    print \"-----------------------------------------------------------------------------\"\n",
      "    print \"Link quality matrix\"\n",
      "    print l\n",
      "    close_friend_calculation(l,size)\n",
      "    \n",
      "def requesting():\n",
      "    global total_request\n",
      "    global total_byte\n",
      "    global sum1\n",
      "    \n",
      "    \n",
      "    peer_id=random.randint(1,num)\n",
      "    peer_id=str(peer_id-1)\n",
      "    print \"Peer \"+peer_id+\" requesting................\"\n",
      "    #request=raw_input(\"Enter the data u want:\")\n",
      "    r1=lines[0]\n",
      "    r1=str(r1)\n",
      "    print \"Peer\"+peer_id+\"requesting data :\"+r1\n",
      "    request=lines[0]\n",
      "    del lines[0]\n",
      "    total_request=total_request+1\n",
      "    n2=request\n",
      "    n2=str(n2)\n",
      "    data=0\n",
      "    data=int(data)\n",
      "    data=r[n2]\n",
      "    total_byte=int(total_byte)+int(data)\n",
      "    cachemanager(request,peer_id) \n",
      "    length=len(lines)\n",
      "   # n=raw_input(\"Do you want to continue,press y\")\n",
      "    if lines[0] != lines[length-1]:\n",
      "        requesting()\n",
      "    else:\n",
      "     garbage=[]\n",
      "     for a in range(0,num):\n",
      "         count=0\n",
      "         values=peer_cache[a].values()\n",
      "         for j in range(0,len(values)):\n",
      "            if values[j]<1.10:\n",
      "             count=count+1\n",
      "         garbage.append(count)\n",
      "         print values\n",
      "     print garbage\n",
      "     getcontext().prec = 6\n",
      "     hr=Decimal(cache_request)/Decimal(total_request)\n",
      "     h=hr*100\n",
      "     h=str(h)\n",
      "     print \"------------------------------------------------------------\"\n",
      "     print \"Hit Ratio:\" + h\n",
      "     print \"------------------------------------------------------------\"\n",
      "     getcontext().prec = 6\n",
      "     bhr=Decimal(cache_byte)/Decimal(total_byte)\n",
      "     bhr=bhr*100\n",
      "     bhr=str(bhr)\n",
      "     print \"------------------------------------------------------------\"\n",
      "     print \"Byte Hit Ratio:\" + bhr\n",
      "     print \"------------------------------------------------------------\"\n",
      "     sum1=0\n",
      "     for a in garbage:\n",
      "            sum1=sum1+a\n",
      "     avg=sum1/num\n",
      "     ppr=float(avg)/float(sum1)\n",
      "     p=ppr*100\n",
      "     p=str(p)\n",
      "     print \"------------------------------------------------------------\"\n",
      "     print \"Pollution Percentage Rate:\"+p\n",
      "     print \"------------------------------------------------------------\"\n",
      "    \n",
      "     print \"Thank you...........\"\n",
      "     print \n",
      "     \n",
      "\n",
      "N = raw_input(\"Enter the Size.of peer cache:\")\n",
      "N=int(N)\n",
      "       \n",
      "lines=open('request.txt','r').read().split('\\n')   \n",
      "num = raw_input(\"Enter the No.of peer cache:\")\n",
      "num=int(num)\n",
      "inter_meeting=[]\n",
      "inter_meeting_time_matrix(num)\n",
      "#close_friend_calculation(inter_meeting)\n",
      "#close_\n",
      "\n",
      "for i in range(0,num):\n",
      "    data_store_i={}\n",
      "    datastore_init(data_store_i,i)\n",
      "    \n",
      "print \"-------------------------------------------------------------------------\"       \n",
      "print \"Peer caches\"\n",
      "\n",
      "print peer_cache  \n",
      "print \"-----------------------------------------------------------------------------\"\n",
      "decn()\n",
      "requesting()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "Missing parentheses in call to 'print' (<ipython-input-1-31e24fc5f8da>, line 48)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-31e24fc5f8da>\"\u001b[0;36m, line \u001b[0;32m48\u001b[0m\n\u001b[0;31m    print data_store_pa\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}